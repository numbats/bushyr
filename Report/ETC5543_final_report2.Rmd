---
title: "Development of Bushfire risk prediction web app Victoria using open data"
author: "Brenwin"
date: "02/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# --- load libraries
library(tidyverse)
library(patchwork)
library(tmap)
library(knitr)
library(kableExtra)
library(tidymodels)
library(GGally)
library(ranger)
library(kableExtra)
library(lime)
library(raster)
library(gridExtra)
library(tmap)
library(lubridate)
```

```{r}
# --- load relevant variables 
load(here::here("VICfire/data/eda_report.Rdata"))
load(here::here("VICfire/data/ida_report.Rdata"))
```

1. Introduction & Motivation
2. Data sources & processing
3. Model Building
4. App (user-interface)
5. Summary & future work


# Introduction and Motivation
    
    H
Bushfire is an intrinsic part of Australia’s environment (https://www.ga.gov.au/scientific-topics/community-safety/bushfire) and it has been a massive issue in Australia as it has caused significant damages in property, life as well as the nature. There have been some catastrophic bushfire events in the past including Black Saturday 2009 in Victoria, Ash Wednesday 1983 in Victoria and South Australia, the 2006 December bushfires, as well as the recent 2019-2020 bushfires. Canada, USA, Turkey, Greece, Italy and Russia faced a devastating bushfire season in the summer of 2021 since it was the hottest July ever recorded, raising concern for Australia since it is moving into summer. Especially since the 2019-2020 bushfire in Australia resulted to more damages on property and the environment compared to other bushfire events in history, with 3094 houses destroyed and over 17M hectares of land burned (Lisa Richards, Nigel Brew and Smith, 2020). 

Even though bushfires cannot be avoided naturally, their consequences can be minimised. Thus, it is important to predict the risk of bushfire as understanding the risk of fire of certain areas would help in developing strategies for mitigating the risks. A prediction model can tell us whether an area has a high risk of bushfire, and we can focus on areas with high fire risk. We will use certain modeling methods to come up with the most suitable model for predicting the bushfire risk. 

This work will focus on Victoria. It is based on Weihao Li’s thesis titled “Using Remote Sensing Data to Understand Fire Ignitions in Victoria during the 2019-2020 Australian Bushfire Season” (citation). Weather is considered a determinant for forest fires (Brown et al. 2008). Therefore, we will be using environmental variables such as temperature, relative humidity, wind speed, radiation, drought index, etc in our modelling as the predictors. We will be testing if these variables are significant for predicting the risk of bushfire in Victoria. 

Fire risk is defined as the likelihood of a fire occurring, multiplied by the severity of the fire (https://www.merton.gov.uk/assets/Documents/www2/fire_safety_risk_assessment_-_june_2013.pdf). However, in this case, we will be defining fire risk as only the likelihood of fire occurring. 
The overall objectives of this work are to develop a web app by using shiny to monitor potential fire ignitions by developing fire risk models for the 2021-2022 Victorian bushfire season based on environmental variables in where users would be able to input the values of the environmental variables which would change the risk predictions. 

    B
Bushfires is a common and natural phenomenon that occurs frequently in many places around the world. Victoria however, is one of the most fire-prone region in the world, given its fire conducive weather and fuel conditions. Fire ignitions are most commonly caused naturally by lightning or can also be man-made such as through planned burning off, accidents or arson.

This report condenses the research work on bushffire risk modelling done by Brenwin Ang and Helen Evangelina as part of their internship for ETC5543 Business Analytics Creative Acitivity coursework. An extension to the work done by Di Cook, Emily Dodwell and Patrick Li on hotspot clustering algorithm. The overall goal to develop a Shiny web application and process to predict bushfire risk across Victoria, Australia. The github repository including Patrick’s thesis can be found here.

The resulting app seeks to improve accessibility to bushfire information, raise awareness to bushfires and provide data information to make informed decisions to better adapt to the many impacts of climate change.


# Data sources & processing

**Map of Victoria**
```{r vic_grid, fig.cap="Victoria bounding box gridded 20 by 20"}
# --- make tmaps interactive
tmap::tmap_mode("view")

# --- plot Victoria map; in 20x20 grid cells
as(vic_raster_crop_values_join$id, "SpatialPolygonsDataFrame") %>% # random raster; with Victoria bbox
  sf::st_as_sf() %>% 
  tmap::tm_shape() +
  tmap::tm_polygons(alpha = 0.3,
                    id = "id") +
  # --- draw outline of Victoria
  tmap::tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) + # line width
  tmap::tm_layout(main.title = "Map of Victoria in 20x20 grid cells") +
  tmap::tm_basemap(leaflet::providers$OpenStreetMap)
```

The following data analysis is based on the map of Victoria that is divided into 20x20 cells (shown above). Note that only cells within Victoria were considered. Our study also only focuses on bushfire seasons where most fire ignitions happen which is from October through to March and data from 2016 to 2021. 



The data used for this project is the satellite hotspots data, which is collated with environmental variables data from SILO, ERA5, BoM, DELWP, and roads data (?).

**Fire ignitions data**

**First respondent fire data (historical fire data) & Satellite data**

    H
We use the historical bushfire ignition locations and causes from the Victorian Department of Environment, Land, Water and Planning (DELWP) Fire Origins and compare it with the hotspot data from Himawari-8 to see which data is more accurate to be used in our modelling. This dataset provides the locations and causes of historical bushfire ignitions reported by the first respondent. These locations are recorded by crews rather than the exact origin of fire.

Hotspot data from Himawari-8 satellite (P-Tree System, 2020) provides a high temporal and spatial resolution. This data can be taken from the Japan Aerospace Exploration Agency FTP site. Himawari-8 data is a remote sensing data which are collected by remote sensors carried by a satellite. The reason we compare the Himawari-8 satellite data with the historical bushfire data is that there are some bushfires start in very remote areas which are virtually impossible to access. Remote sensing data provides a possible solution for this, and it may provide a more accurate locations of bushfire ignitions. Himawari-8 data has a 10-minute time resolution.

    B
Fire ignitions are represented as spatial points on the map. There were two sources of bushfire ignitions data.

Firstly, hotspot satellite data from Himawari-8 satellite. Fire ignitions were detected using a clustering algorithm able to detect fires in real-time. (more information available in Patrick’s github). Secondly, historical First Responder’s data, this can be thought of as fires reported upon sight. That is, the First Respondent’s data was based on where the first responder saw the fire. Most of these were reports from volunteers manning fire towers erected around Victoria. (see appendix for map of fire towers around Victoria). Below shows fire ignitions data overlayed onto griided map of Victoria. 


```{r ignition-pts, fig.cap="fire ignitions represented as points on Victoria map"}
# from eda's `cluster_map_facet_bf_season`
cluster_map_bf_season <- ignition_rasterize_cluster_bf_season %>% 
  mutate(fire_count = case_when(
    fire_count == 0 ~ NA_real_,
    TRUE ~ fire_count)) %>% 
  filter(bf_season == "2019-2020") %>% 
  tmap::tm_shape(name = "cell fire ignition count") +
  tmap::tm_polygons(col = "fire_count",
                    id = "id",
                    style = "fixed",
                    breaks = c(0, 10, 20, 30, 40, 50),
                    palette = "YlOrRd",
                    alpha = 0.4,
                    colourNA = "grey",
                    legend.show = F) + 
  
  # --- add ignition points (to buffer as necessary)
  tmap::tm_shape(cluster_16_21_sf %>% filter(bf_season == "2019-2020"),
                 name = "fire ignition points") +
  tmap::tm_bubbles(# col = "cause",
                   size = 0.3,
                   alpha = 0.1,
                   id = "") +
  
  # --- vic_map_sf (draw outline of Victoria )
  tmap::tm_shape(vic_map_sf,
                 name = "Victoria map outline") +
  tmap::tm_borders(lwd = 3) + # border line width 
  
  # --- themes
  tmap::tm_layout(legend.show = F) +
  tm_basemap(leaflet::providers$OpenStreetMap) +
  tmap::tm_layout(main.title = "number of bushfire ignitions across Victoria")

cluster_map_bf_season
```

**Climate and landscape data**

    H
**ERA5 weather data**

**Fuel layer**
The fuel layer data is obtained from the 2018 nationwide forest dataset from Australian Bureau of Agricultural and Resource Economics and Services (2018). This data consists of a continental spatial dataset of forest extent by national forest categories and types. A forest variable is used as a predictor in our model in where 0 indicates that the grid cell is not a forest and 1 if otherwise.

    B
```{r var-tab}
tibble::tribble(~source, ~variables, ~format, ~temporal_resolution,
                "SILO (https://www.longpaddock.qld.gov.au/silo/)", "max_temp, rh, radiation, et_short_crop, daily_rain", "NetCDF", "daily",
                
                "ERA5 Reanalysis data (https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=overview)", "lai_hv, lai_lv, WS10", "NetCDF" ,"monthly",
                
                "BoM's AWRA-L (http://www.bom.gov.au/water/landscape/#/sm/Actual/month/-26.32/132.54/3/Point/Separate/-15.6/130.25/2021/4/30/)", "s0_pct", "NetCDF", "monthly",
                
                "Department of Environment, Land, Water and Planning (DELWP) (https://discover.data.vic.gov.au/dataset/forest-types-of-victoria)", "vic_forest", "ShapeFile", "Periodic") %>% 
  knitr::kable(caption = "data source, variables, format and temporal resolution used in this study") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


In this analysis, 11 variables are considered to identify their influence on bushfires. These variables are: maximum temperature (`max_temp`), relative humidity (`rh`), solar radiation (`radiation`), derived FAO56 short crop evapotranspiration rate in mm (`et_short_crop`), daily rainfall (`daily_rain`), leaf area index in high vegetation in $m^2 \ m^{-2}$ (`lai_hv`), leaf area index in low vegetation in $m^2 \ m^{-2}$  (`lai_lv`), 10m wind speed in $m\ s^{-1}$ (`WS10`) and  forest type in Victoria (`vic_forest`). All the variables were converted into monthly data by taking its mean. 

All the spatial data are converted into gridded form (`raster`) to match the 20x20 gridded Victoria map in Figure \@ref(fig:vic_grid). To achieve this for numeric variables (all except `vic_forest`), since the resolution provided from the data sources were much finer than required, all the finer cells contained in the larger grid cell are averaged. For `vic_forest`, any cells that contains a forest is set to 1, 0 otherwise. An example for a the variable `max_temp` is shown in Figure \@ref(fig:max-temp). 


```{r max-temp, fig.cap="Average max temperature for the month of May 2021"}
max_temp_raster_crop %>% 
  raster::reclassify(rcl = cbind(NA, 0)) %>% # reclassify NA values to 0
  # raster -> spdf -> sf
  as(., "SpatialPolygonsDataFrame") %>% 
  sf::st_as_sf() %>%
  dplyr::select(X2021.05.01:X2021.05.31) %>% 
  # pivot_longer; change to tibble; since `pivot_longer` not compatible with `sf` yet
  as_tibble() %>% 
  mutate(id = 1:400,
         .before = "X2021.05.01") %>% 
  tidyr::pivot_longer(cols = X2021.05.01:X2021.05.31,
                      names_to = "date",
                      values_to = "max_temp") %>% 
  # to `sf`
  sf::st_as_sf() %>% 
  group_by(id) %>% 
  summarise(mean_max_temp = mean(max_temp)) %>% 
  tmap::tm_shape(.,
                 name = "max_temp cell") +
  tm_polygons(col = "mean_max_temp",
              alpha = 0.5) +
  
  tmap::tm_shape(vic_map_sf,
                 name = "Victoria map outline") +
  tmap::tm_borders(lwd = 3) + # line width
  
  tm_layout(main.title = "Map of Victoria in 20x20 grid cells") +
  tm_basemap(leaflet::providers$OpenStreetMap) +
  tmap::tm_layout(main.title = "Mean Max Temperature Across Victoria for May 2021")
```


## Data Processing
### Himawari-8 hotspot data
The hotspot data from Himawari-8 firstly needs to be selected to those within the boundary of Victoria. To reduce noise, it is then filtered based on the fire power with a recommended threshold of over 100 (irradiance over 100 watts per square metre) (Williamson, 2020). 

The hotspot data from Himawari-8 needs to be grouped into clusters because some hotspots are branches of an existing bushfire. Therefore, we use spatio-temporal clustering to group the hotspots into clusters. Clustering algorithm used in this project is based on Weihao Li’s thesis (citation & reference), inspired by two existing clustering algorithm, Density Based Spatial Clustering of Applications with Noise (DBSCAN) (Ester et al., 1996) and Fire Spread Reconstruction (FSR) (Loboda and Csiszar, 2007). 

The issue with using DBSCAN for clustering hotspot data is its algorithm assumes the clustering rules work in both directions of a timeline, which does not capture the reality that bushfires evolve over time in one direction. It is not suitable for temporal data. FSR reconstructs bushfire spread well, however it is constructing the clusters sequentially. This means that FSR will consider two fires to be a single fire if they commence at different locations but they overlap. Because of this, FSR does not reflect the real speed of bushfire correctly. Other limitation of FSR is that it lacks detailed consideration of parameter tuning. Weihao Li’s clustering algorithm is inspired by these two algorithms, and it can efficiently and robustly cluster hotspot to consider the temporal behavior of bushfires.

There are four steps in the clustering algorithm. The first step is to slice the temporal dimension based on a parameter named ActiveTime. Next, the hotspots are clustered spatially by using a parameter called AjdDist, which reflects the potential distance a fire can spread with respect to the temporal resolution of the data. Hotspots in the same component will be assigned a unique membership id. The third step is to broadcast the clustering results and update the membership label. Lastly, the ignition locations are computed with the earliest observed hotspot indicates the ignition point. If there are several earliest hotspots, the centroid of these points is used. 

The clustering algorithm slices the data by its temporal dimension and splits the spatio-temporal clustering tasks into thousands spatial clustering tasks. The result of the clustering is a dataset consisting of four variables – unique identifier, longitude, latitude, and time. The final hotspot data used for this project consists of 2,917 observations from 2016 to 2021. 


**Data integration**
– Talks about lagged variables bcs this might be important. The risk of fire happening might be affected by the average weather conditions for the two months or even a year. A hotter and drier year might result to more fires than –

# Model Building

**Comparison of Hotspot and Historical Fire Data**

    H
As previously stated, historical fire data might not represent the accurate locations of the bushfire ignitions. Fire might start in a remote location which might be hard to visually access or monitor. Therefore, to choose which fire data to use for our modelling, we do comparisons on the historical fire data and the satellite data. The satellite data used here is the clustered satellite data.
```{r}
training <- read.csv(here::here("VICfire/data/training.csv"))
  
  training <- training %>%
    filter(!CAUSE %in% c("BURNING BUILDING",
                         "WASTE DISPOSAL, INDUSTRIAL, SAWMILL, TIP",
                         "WASTE DISPOSAL, DOMESTIC",
                         "BURNING VEHICLE, MACHINE",
                         "BURNING BUILDING")) %>%
    filter(new_cause != "other") %>%
    filter(new_cause != "relight")
  
  
  training <- dplyr::select(training, -c(EVENTID:FIRE_NUM), -id, -CAUSE, -FOREST, -FOR_CODE, -FOR_CAT)
  
  training <- mutate(training,
                     year = factor(year(FIRE_START)),
                     month = factor(month(FIRE_START), levels = c(10,11,12,1,2,3)),
                     day = factor(day(FIRE_START), levels = c(1:31)),
                     wod = factor(wday(FIRE_START), levels = c(1:7)))
  
  training <- filter(training, month %in% c(10,11,12,1,2,3))
  
  training <- na.omit(training)
  
  training <- mutate(training, new_cause = ifelse(new_cause == "accidental_human", "accident", new_cause)) %>%
    mutate(new_cause = ifelse(new_cause == "burning_off_human", "burning_off", new_cause)) %>%
    mutate(new_cause = factor(new_cause)) %>%
    mutate(FOR_TYPE = factor(FOR_TYPE))
  
  training <- na.omit(training)
  
  training <- mutate(training,
                     log_dist_cfa = log(dist_cfa),
                     log_dist_camp = log(dist_camp),
                     log_dist_road = log(dist_road),
                     COVER = factor(COVER),
                     HEIGHT = factor(HEIGHT))
  
  training <- rename(training, cause = new_cause)
  training <- mutate(training,
                     cause = fct_relevel(cause,
                                         "lightning",
                                         "accident",
                                         "arson",
                                         "burning_off"))
  
  training <- na.omit(training)
  
  training <- dplyr::select(training, -dist_road, -dist_cfa, -dist_camp, -FIRE_START)

training2016 <- training %>%
  filter((year == 2016 & month %in% c(10,11,12)) | (year == 2017 & month %in% c(1,2,3)))

training2017 <- training %>%
  filter((year == 2017 & month %in% c(10,11,12)) | (year == 2018 & month %in% c(1,2,3)))
```

```{r, echo = FALSE}
# loading the clustered data
hotspot2016_2018 <- read.csv(here::here("VICfire/data/clustering/predict_x_2016_2018.csv"))
hotspot2019_2020 <- read.csv(here::here("VICfire/data/clustering/predict_x_2019_2020.csv"))

hotspot2016_2018 <- hotspot2016_2018 %>%
  mutate(year = year(time),
         month = month(time))

hotspot2019_2020 <- hotspot2019_2020 %>%
  mutate(year = year(time),
         month = month(time))

hotspot2016 <- hotspot2016_2018 %>%
  filter((year == 2016 & month %in% c(10,11,12)) | (year == 2017 & month %in% c(1,2,3)))

hotspot2017 <- hotspot2016_2018 %>%
  filter((year == 2017 & month %in% c(10,11,12)) | (year == 2018 & month %in% c(1,2,3)))

hotspot2018 <- hotspot2016_2018 %>%
  filter((year == 2018 & month %in% c(10,11,12)) | (year == 2019 & month %in% c(1,2,3)))

hotspot2019 <- hotspot2019_2020 %>%
  filter((year == 2019 & month %in% c(10,11,12)) | (year == 2020 & month %in% c(1,2,3)))

hotspot2020 <- hotspot2019_2020 %>%
  filter((year == 2020 & month %in% c(10,11,12)) | (year == 2021 & month %in% c(1,2,3)))
```

```{r, echo = FALSE}
training2017_selected <- training2017 %>%
  dplyr::select(lon, lat, year, month) %>%
  mutate(type = "training")

hotspot2017_2 <- hotspot2017 %>%
  dplyr::select(-id, -time) %>%
  mutate(type = "hotspot")

# converting to factor
hotspot2017_2$year <- as.factor(hotspot2017_2$year)
hotspot2017_2$month <- as.factor(hotspot2017_2$month)

joined_2017 <- training2017_selected %>%
  bind_rows(hotspot2017_2)
```

```{r}
training2016 <- training2016 %>%
  mutate(period = "2016-2017")

training2017 <- training2017 %>%
  mutate(period = "2017-2018")

hotspot2016 <- hotspot2016 %>%
  mutate(period = "2016-2017")

hotspot2017 <- hotspot2017 %>%
  mutate(period = "2017-2018")

training2016_2017 <- training2016 %>%
  bind_rows(training2017) %>%
  dplyr::select(lon, lat, year, month, period) %>%
  mutate(type = "training")

hotspot2016_2017 <- hotspot2016 %>%
  bind_rows(hotspot2017) %>%
  mutate(type = "hotspot")

# converting to factor
hotspot2016_2017$year <- as.factor(hotspot2016_2017$year)
hotspot2016_2017$month <- as.factor(hotspot2016_2017$month)

joined_all <- training2016_2017 %>%
  bind_rows(hotspot2016_2017)
```

```{r comparison-plot, fig.cap= "A comparison of the monthly number of fires in the hotspot data and the historical data for 2016-2018."}
#comparing distribution
joined_all %>%
  count(month,year, type, period) %>%
  group_by(type, year, period) %>%
  ggplot(aes(x = month,
             y = n)) +
  geom_bar(aes(fill = type), position = "dodge", stat = "identity") +
  ggtitle("Comparison of historical vs satellite data") +
  facet_grid(~period) +
  ylab("Number of fires")
```

Figure \@ref(fig:comparison-plot) illustrates the comparison of the number of fires from the satellite data and the historical fire data for the period 2016-2017 and 2017-2018. There are more hotspot data for the period of 2016-2017 in January, February and March, and more historical data for October, November, and December. Meanwhile for period 2017-2018, the historical dataset has more observations overall except for March. One obvious insight here is that the number of observations is not consistent monthly, indicating that month is an important factor in determining the risk of fire. The number of bushfires in November and December from the satellite data is significantly lower compared to the historical data, which might be due to the filtering of fire power to only include big fires. 

```{r}
# traaining data
training2017_2 <- training2017
coordinates(training2017_2) = c("lon", "lat")

x1 <- raster(xmn = 141,
            xmx = 150, 
            ymn = -39,
            ymx = -34,
            res = 0.4, 
            crs = "+proj=longlat +datum=WGS84")

x1[] <- 0

tab1 <- table(cellFromXY(x1, training2017_2))

x1[as.numeric(names(tab1))] <- tab1

# creating proportions
df1 <- data.frame(coordinates(x1), count = x1[])
df1 <- df1 %>% 
  mutate(prop2017 = count/947)  %>%
  dplyr::select(-count)

# clustered hotspot data
hotspot2017_2 <- hotspot2017
coordinates(hotspot2017_2) <- c("lon", "lat")

xh_2017 <- raster(xmn = 141,
            xmx = 150, 
            ymn = -39,
            ymx = -34,
            res = 0.4, 
            crs = "+proj=longlat +datum=WGS84")

xh_2017[] <- 0

tabh_2017 <- table(cellFromXY(xh_2017, hotspot2017_2))

xh_2017[as.numeric(names(tabh_2017))] <- tabh_2017

# creating proportions
dfh_2017 <- data.frame(coordinates(xh_2017), count = xh_2017[])
dfh_2017 <- dfh_2017 %>% 
  mutate(prop_h2017 = count/488)  %>%
  dplyr::select(-count)
```

We also looked at the difference between the historical and satellite dataset per grid cell. Figure \@ref(fig:comparison-map) represents the number of fires in 2017-2018 period for historical (left) and satellite (right) data. We also compared the data for 2016-2017 and the insights we got are similar. There are a lot of fires in the historical data centered around CBD, indicating that there are more fires in areas where there are more people. Meanwhile, the satellite data shows that there are so little fires around the city center which might be due to the filtering of firepower. There are a lot of fires in remote areas which are not captured by the historical data, which might be due to these remote fires not being able to be monitored by people directly.  Satellite data, on the other hand, can capture these fires well. 

```{r comparison-map, fig.cap="The map representation of the fire counts for the historical data (left) and the hotspot data (right) for 2016-2017."}
par(mfrow=c(1,2))
plot(x1)
points(training2017, pch = 20)

plot(xh_2017)
points(hotspot2017_2, pch = 20)
```

To account for the different number of fires each year, we created proportions of fire for each grid cell, which is calculated by dividing the number of fires in that cell for that year divided by the total fires in the year. The result is that there are some differences in the proportions for some cells as seen from figure \@ref(fig:). Some cells have higher proportions for the hotspot data while some others have higher proportions for historical data. Cells with higher proportions for historical data tend to be those areas closer to the city center in where there are a lot of people. On the other hand, cells with higher hotspot proportions are those areas which are more remote. 

```{r proportions-comparison, fig.cap= "The figure shows a scatter plot of the proportions in the hotspot data vs the proportions in the historical data with each point represents the cell id."}
#creating scatter plot
df_joined_2017 <- df1 %>%
  left_join(dfh_2017, by = c("x", "y")) %>%
  mutate(diff = prop2017 - prop_h2017,
         id = 1:264) 

df_joined_2017 %>%
  group_by(x, y) %>%
  ggplot(aes(x = prop2017,
             y = prop_h2017,
             label = id)) +
  geom_text() +
  ggtitle("Proportions of hotspot vs historical data for 2017-2018")  +
  ylab("Proportions of hotspot data") +
  xlab("Proportions of historical data")
```

In conclusion, satellite or hotspot data provides more accurate locations and time of bushfire ignitions as satellite data captures those fires in remote areas not visually accessible by people. There was a big fire in Terang on St Patrick’s Day, 17 March 2018. It destroyed residential properties and damaged farming properties. However, this fire was not recorded in the historical data. For these reasons, we decided to use satellite data for our fire risk modelling. 


      B
```{r fire-bf-month, fig.cap="number of fire ignitions against bushfire seasons(top) and month(bottom)"}
# --- fire ignitions by bushfire season
p1 <- cause_join_count_bf_season %>% 
  filter(bf_season %in% unique(cluster_16_21_count_bf_season$bf_season)) %>% 
  dplyr::select(bf_season, total) %>% 
  # join cluster & join data counts
  right_join(cluster_16_21_count_bf_season,
            by = "bf_season") %>% 
  rename(total_join = total.x,
         total_cluster = total.y) %>% # fire ignitions; in clustering data (2016-2021)
  distinct(bf_season,
           .keep_all = T) %>% 
  dplyr::select(-data) %>% 
  pivot_longer(cols = total_join:total_cluster,
               names_to = "data", # in join (historical(2000-2019) & sat(2019-2020))// cluster(2016-2021)
               values_to = "n") %>% # no. of fire ignitions
  ggplot() +
  geom_col(aes(x = bf_season,
               y = n,
               fill = data),
           position = "dodge",
           width = 0.23) +
  colorspace::scale_fill_discrete_qualitative(labels = c("clustering", "historical")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "Fire ignitions by bushfire season",
       x = "bushfire season",
       y = "number of ignitions")


# --- fire ignitions by month
p2 <- left_join(cluster_16_21_count_month, cause_join_count_month,
          by = c("bf_season", "month")) %>% 
  rename(total_cluster = n.x,
         total_join = n.y) %>% 
  pivot_longer(cols = total_cluster:total_join,
               names_to = "data",
               values_to = "n") %>% 
  ggplot() +
  geom_col(aes(x = factor(month,
                          levels = c(10, 11, 12, 1, 2, 3)),
               y = n,
               fill = data),
           position = "dodge") +
  facet_wrap(. ~ bf_season) + 
  colorspace::scale_fill_discrete_qualitative(labels = c("clustering", "historical")) +
  theme_bw() +
  labs(title = "Fire ignitions each month facet by bushfire season",
       x = "month",
       y = "number of ignitions") 
  

p1 / p2 +
  plot_layout(guides = "collect")
```

    bar plot comparison 
Historical data is available from 2000 up to end of 2020 (note: 2019 data from January to March is missing). While satellite data can be obtained up till the present. The satellite data used here is the clustered satellite data. 

This section compares the agreeableness between both datsets in of number of bushfire ignitions ("points") in each raster grid cell. As we can see, the fire ignitions data sets do not match up exactly largely due to **how** the data was collected.

Number of ignitions in each data set is plotted against bushfire season (top) and month (bottom) in Figure \@ref(fig:fire-bf-month) above. The lack of agreeableness both the datasets is apparent. In particular, there were considerably more bushfire ignitions in 2016-2017 bushfire season in the clustering data especially in the months January to March. Meanwhile in 2017-2018, there were more observations in the historical data set except for March. 

```{r}
# join no. of fires per cell; for historical & cluster data
dplyr::inner_join(ignition_rasterize_training_sf_bf_season, ignition_rasterize_cluster_bf_season %>% sf::st_set_geometry(NULL),
           by = c("id", "bf_season")) %>%
  rename(fire_count_training = fire_count.x,
         fire_count_cluster = fire_count.y) %>% 
  # compute difference = historical - cluster
  mutate(diff = fire_count_training - fire_count_cluster) %>% 
  mutate(diff = case_when(
    diff == 0 ~ NA_real_,
    TRUE ~ diff
  )) %>% 
  tmap::tm_shape(name = "fire_count diff") +
  tmap::tm_polygons(col = "diff",
                    palette = "RdBu",
                    n = 6,
                    group = "diff",
                    id = "id",
                    alpha = 0.6) +
  # facet by bushfire season  
  tmap::tm_facets(by = "bf_season",
                  ncol = 1) +
  
  # include Vic map outline
  tmap::tm_shape(vic_map_sf,
                 name = "Victoria map outline") +
  tmap::tm_borders(lwd = 3) +
  
  # baselayer
  tmap::tm_basemap(leaflet::providers$OpenStreetMap)
```

    
    Spatial distribution comparison 
We also compared differences in the spatial distributions of ignitions in both the data sets by computing the difference in number of ignitions (points) contained within in cell i.e. historical ignitions - satellite ignitions per cell.

The results is shown in the plot above. There is obvious differences in how the fire ignitions are scattered around the map. Historical data is more concentrated in the map while satellite data tend to be more scattered. There is also strikingly more observations near Melbourne CBD for historical data sets. Moreover, zooming in, we observe that most of ignitions observed in the historical data are highly accessible by road while places where there is a much larger number for satellite data are in the remote areas. This speaks to the fact that most ignitions are caused by lightning (https://theconversation.com/open-data-shows-lightning-not-arson-was-the-likely-cause-of-most-victorian-bushfires-last-summer-151912).


    Conclusion
There are a few hypothesis pertaining to the inaccuracies of the historical data. Firstly, it is difficult to distinguish the number of fires one observes with the naked eye. For the same reason, it is less accurate and more subjective to gauge the location of a fire. Recording bushfires in this manner also prevents remote areas from being surveyed. Equally important is that we might also need to check the consistency of fire tower manning at each station. Another thing to note is that the number of bushfires is significantly lower from October to November, this could be due to filtering the clustered satellite data to include only bigger fires. 

**Modelling**
The most common choice for bushfire risk modelling is the generalised additive model (GAM), which is used by Bates, McCaw, and Dowdy (2018) to predict the number of lightning ignitions in Western Australia. Simpler parametric models have also been used to predict the risk of bushfire, including multiple linear regression and generalized logistic regression.  The predictors used for these models are environmental variables like weather variables and vegetation types. *However, none of the models use hotspot data to predict the risk of bushfire. *? 
We use models like linear regression model, random forest, and lasso regression model to predict the risk of bushfire in Victoria by using the hotspot data. Firstly, we fit a simple linear model to obtain a general insight of the data. We use all variables in the final dataset, which have been explained before, as our predictors. These variables are chosen based on our research about past bushfire risk modelling. This model provides some interesting insights with some predictors being not significant for the model. Average rainfall for that month has a positive correlation with the number of fires while average rainfall for the two months and three months have a negative correlation with the number of fires. Similar thing with maximum temperature, where average maximum temperature for the month and for the two months have a positive relationship with fire counts while average maximum temperature in three months has a negative relationship. This might be due to the non-linear relationship between environmental variables and fire counts. By fitting a linear model, we are assuming that the relationship between the predictors and the response is linear, when in reality it is not. As expected, the linear model has an adjusted R-squared of 0.1219. We also fitted a linear model with a log scale of fire_count, which makes it slightly better with a 0.1709 Adjusted R-squared. This indicates that only 17.09% variations in the data are explained by the model, thus a linear regression is not a good model for predicting the risk of bushfire.

Random forest (Breiman, 2001) is a supervised learning technique that is constructing hundreds of regression trees by using ensemble learning, combined to a robust prediction model. It consists of a large number of decision trees, which are combined by taking the mean of the predicted y values as the prediction of all trees. A random forest model is built from a bootstrap sample of the data. Each tree at each parent node is constructed from p randomly selected predictors (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229509). The trees run in parallel without any interactions amongst them (https://levelup.gitconnected.com/random-forest-regression-209c0f354c84). Random forest is well suited for non-linear relationships, which is suitable for our case as the relationship between environmental variables and the fire risk is non-linear. In this case, we are using random forest for regression problem in where the splitting in each node is based on minnimising RSS.

An issue with modelling the risk of bushfire based on environmental variable is the collinearity between variables. For example, relative humidity changes when temperature changes. An evidence of multicollinearity in our data can be seen in \@ref(fig:collinearity). Random forest model can handle multicollinearity problem well as it offers protection against the impact of collinearity between predictors (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4710485/)/. The reason for this is because random forest only considers a subset of predictors at each split, resulting to decorrelated trees. Even though multicollinearity is not a problem for the random forest algorithm itself, it might be a problem for the variable importance. Feature importance might be affected by multicollinearity as the importance of variables with high collinearity will be offset by each other. 

```{r collinearity, fig.cap= "The figure shows the correlation matrix of the variables in our data. There are some variables in our data with high correlations, such as radiation has a really high correlation with et_short_crop (0.9)." }
data_corr <- train %>%
  ungroup() %>%
  dplyr::select(-id, -year) 
ggcorr(data_corr, label = T)
```

```{r}
# creating a raster for victoria
vic_raster <- raster(
  # no. of rows & columns (directly linked to resolution of grid cell)
  nrows = 20,
  ncols = 20,
  
  # bbox (bounding box of Victoria)
  xmn = 140.9617,
  xmx = 149.9763,
  ymn = -39.13396,
  ymx = -33.99605,
  
  # crs
  crs = "+proj=longlat +datum=WGS84"
  )
vic_raster[] <- 1:ncell(vic_raster)

# creating the lon & lat for each cell id
lonlat <- as.data.frame(coordinates(vic_raster)) %>%
  mutate(id = as.factor(1:400))

```

For the purpose of modelling, we split the data into training and test set. The training set consists of those data for 2016-2020, while the test set consists of the data for 2020-2021. Splitting data to training and test set is important in model building to check the accuracy of the model and prevent over-fitting or underfitting. A model might perform well in the training set, but not perform well once it is applied to the test set. The accuracy of our model can be tested using the test set. In this case, we use the most recent year as our test set because the 2021-2022 is more likely to be similar to 2020-2021. The reason we chose to use different bushfire period as the test set is because we want to see if our model can provide a good prediction for different periods.

Based on our previous analysis, month is an important variable in determining the risk of fire as the risk of bushfire differs monthly. We treated month as a factor variable in our model. We fitted a random forest model with all the variables in our dataset as the explanatory variables. Our first random forest model is a model fitted using `ranger` (citation) without specifying the number of trees (ntree) and the number of variables used in each tree (mtry). The result is a random forest model by using 500 ntree and 5 mtry. This model has a mean of squared residuals of 1.216 and R-squared of 0.396. Test MSE resulted from this model is 1.242 with an R-squared of 0.22, indicating that random forest is better than a linear regression model. Summary statistics of the test set on the random forest model is on \@ref(tab:test-summary).

```{r}
train_final <- train %>% 
  left_join(lonlat, by = "id") %>%
  dplyr::select(-year) %>% mutate(month = as.factor(month))

set.seed(2021)
randomforest1 <- ranger(fire_count ~ .-id, data = train_final, importance = "impurity")
```

```{r test-summary, fig.cap="Summary statistics of the random forest model on test set."}
test2 <- test %>%
  left_join(lonlat, by = "id") %>%
  dplyr::select(-id, -year) %>%
  mutate(month = as.factor(month))

predicted <- predict(randomforest1, test2)$predictions

# Function for evaluating model
model_summary <- function(truth, estimate){
  
  df_new <- data.frame(truth = truth,
                       estimate = estimate)
  
  data.frame(RMSE = rmse_vec(truth, estimate),
             MAE = mae_vec(truth, estimate),
             "R-Square" = rsq_vec(truth, estimate),
             check.names = F
             ) %>% 
    mutate(MSE = sqrt(RMSE))
}

kable(model_summary(truth = test2$fire_count,
           estimate = predicted))
```

## Features Selection

We explored if only including the important variables would make the model better. As stated before, the variable importance on a random forest with multicollinearity in the data could not really be trusted. Therefore, we used `lime` (citation) to understand which variables contribute most to the prediction of bushfire risk. Local Interpretable Model-agnostic Explanation (LIME) can explain the predictions of a regression problem in an interpretable manner, which is done by learning an interpretable model locally around the prediction (https://algotech.netlify.app/blog/interpreting-black-box-regression-model-with-lime/). We split our data into data with high fire counts and data with low fire counts. Then, we sampled 4 observations from each data,  which will be passed to the `explain` function. 


```{r}
set.seed(2021)
train2 <- train_final %>% dplyr::select(-fire_count)

explainer <- lime(x = train2,
                  model = randomforest1) 

# dealing with model_type error
model_type.randomForest <- function(x){
  return("regression") # for regression problem
}

predict_model.randomForest <- function(x, newdata, type = "response") {

    # return prediction value
    predict(x, newdata) %>% as.data.frame()
    
}

# sampling data
data_low <- train_final %>% filter(fire_count < 5)
data_high <- train_final %>% filter(fire_count>5)

set.seed(2021)
lime_sample1 <- sample(1:length(data_low),4)
lime_sample2 <- sample(1:length(data_high),4)

data_selected1 <- data_low[lime_sample1, ]
data_selected2 <- data_high[lime_sample2, ]
data_selected <- data_selected1 %>% bind_rows(data_selected2) %>%
  dplyr::select(-fire_count)

# creating explanation
explanation <- explain(x = data_selected,
                       explainer = explainer, 
                       feature_select = "auto",
                       n_features = 15)

explanation1 <- explanation %>% filter(case %in% c(1,2,3,4)) 
explanation2 <- explanation %>% filter(case %in% c(5,6,7,8)) 
```

```{r plot-features, fig.cap= "The figure illustrates the variables which are deemed as important in predicting the fir risk for the low fire counts."}
plot_features(explanation1)
```

```{r plot-features2, fig.cap= "The figure illustrates the variables which are deemed as important in predicting the fir risk for the high fire counts."}
plot_features(explanation2)
```

Figure \@ref(fig:plot-features) illustrates the predictors which explain most of the fire risk prediction for the low fire counts with the x-axis showing the relative magnitude and direction of each predictors. While figure \@ref(fig:importance-rf2) shows those for the high fire counts. It can be seen that forest and month are really important in both cases, followed by surface soil moisture (s0_pct), wind speed (si10), and radiation. The top 15 features  are mostly the same for all the observations. We used these important features to fit a random forest model, however this new model has a higher mean of squared residuals. Hence, we decided to proceed with the random forest model with all of the variables. 

## Parameters tuning
To increase the accuracy of our model, we did paramaters tuning by using the `tuneRanger` package (citation) to find the best values of parameters for our model. Lowest error is achieved when mtry is equal to 8 and ntree equal to 500. We then fitted another random forest with these parameters and all of the predictors, which resulted to a 1.212 mean of squared error and R-squared of 0.399, which is slightly better than the previous model. After applying the model to the test set, we get a slightly higher MSE (1.243) and a slightly lower R-squared (0.21), indicating that the tuned model is slightly worse than the previous model. Summary statistics of the tuned model on the test set can be seen on table \@ref(tab:test-summary2) Even though the tuned model performs better on the training set, it performs worse on the test set. This indicates that the tuned model might over-fit the training set, therefore we choose to go with the un-tuned model.

```{r test-summary2, fig.cap="Summary statistics of the random forest model on test set."}
set.seed(2021)
randomforest2 <- ranger(fire_count ~ .-id, data = train_final, importance = "impurity",num.threads=8,verbose=FALSE,mtry=8,min.node.size=2,num.trees=500,replace=FALSE)

predicted2 <- predict(randomforest2, test2)$predictions

kable(model_summary(truth = test2$fire_count,
           estimate = predicted2))
```


To evaluate our model more, we calculated the residuals and plotted them against the predicted values. There are some high residuals, indicating that the model is not predicting some observations well. Figure \@ref(fig:map-rf1) shows the representation of the actual monthly fire counts and predicted fire counts on the training set. One clear thing to notice here is that our model tends to under-predict the fire counts, especially in March. Figure \@ref(fig:map-rf-test) shows the comparison for the test set. The predictions for the test set do not really capture the observed fire counts, which might be due to the different situations in 2020-2021. 2020-2021 has a higher number of fires, especially in January and March, which needs to be further explored in future works. Our model under-predicts the fire counts. Looking at the proportions of fire instead of counts might be better because looking at the pattern on the map, our model predicts those cells with higher observed fire counts to have higher predicted fire counts compared to others.

```{r}
rf2_data <- train_final %>% bind_cols(pred = randomforest1$predictions) %>% 
  mutate(resid = fire_count - pred)

mean_data <- rf2_data %>%
  group_by(id, month) %>%
  summarise(pred_count = mean(pred),
            count = mean(fire_count))

mean_oct <- mean_data %>% filter(month == 10) %>%
 left_join(lonlat)

mean_oct <- mean_oct %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_oct) = c("x", "y")
mean_oct_raster <- rasterFromXYZ(mean_oct)

pred_oct <- tm_shape(mean_oct_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,breaks = c(0,1,2)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)  +
  tm_layout(legend.position = c("right","top"))

# actual data
dataframe <- data.frame(id = as.factor(1:400)) 

oct_data <- train %>%
  filter(month == 10) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

oct_data <- dataframe %>%
  left_join(oct_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

oct_data <- oct_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(oct_data) = c("x", "y")
oct_raster_actual <- rasterFromXYZ(oct_data)

actual_oct <- tm_shape(oct_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,breaks = c(0,1,2)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_legend(show = FALSE) +
  tm_layout(title = "October")

mean_nov <- mean_data %>% filter(month == 11) %>%
 left_join(lonlat)
mean_nov <- mean_nov %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_nov) = c("x", "y")
mean_nov_raster <- rasterFromXYZ(mean_nov)

pred_nov <- tm_shape(mean_nov_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,1.2)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)  +
  tm_layout(legend.position = c("right","top"))

# actual data
nov_data <- train %>%
  filter(month == 11) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

nov_data <- dataframe %>%
  left_join(nov_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

nov_data <- nov_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(nov_data) = c("x", "y")
nov_raster_actual <- rasterFromXYZ(nov_data)

actual_nov <- tm_shape(nov_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,1.2)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "November")

mean_dec <- mean_data %>% filter(month == 12) %>%
 left_join(lonlat)
mean_dec <- mean_dec %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_dec) = c("x", "y")
mean_dec_raster <- rasterFromXYZ(mean_dec)

pred_dec <- tm_shape(mean_dec_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)  +
  tm_layout(legend.position = c("right","top"))

# actual data
dec_data <- train %>%
  filter(month == 12) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

dec_data <- dataframe %>%
  left_join(dec_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

dec_data <- dec_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(dec_data) = c("x", "y")
dec_raster_actual <- rasterFromXYZ(dec_data)

actual_dec <- tm_shape(dec_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)+
  tm_legend(show = FALSE) +
  tm_layout(title = "December")

mean_jan <- mean_data %>% filter(month == 1) %>%
 left_join(lonlat)
mean_jan <- mean_jan %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_jan) = c("x", "y")
mean_jan_raster <- rasterFromXYZ(mean_jan)

pred_jan <- tm_shape(mean_jan_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)  +
  tm_layout(legend.position = c("right","top"))

# actual data
jan_data <- train %>%
  filter(month == 1) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

jan_data <- dataframe %>%
  left_join(jan_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

jan_data <- jan_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(jan_data) = c("x", "y")
jan_raster_actual <- rasterFromXYZ(jan_data)

actual_jan <- tm_shape(jan_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)+
  tm_legend(show = FALSE) +
  tm_layout(title = "January")

mean_feb <- mean_data %>% filter(month == 2) %>%
 left_join(lonlat)
mean_feb <- mean_feb %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_feb) = c("x", "y")
mean_feb_raster <- rasterFromXYZ(mean_feb)

pred_feb <- tm_shape(mean_feb_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,1.5)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)  +
  tm_layout(legend.position = c("right","top"))

# actual data
feb_data <- train %>%
  filter(month == 2) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

feb_data <- dataframe %>%
  left_join(feb_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

feb_data <- feb_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(feb_data) = c("x", "y")
feb_raster_actual <- rasterFromXYZ(feb_data)

actual_feb <- tm_shape(feb_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,1.5)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_legend(show = FALSE) +
  tm_layout(title = "February")

mean_mar <- mean_data %>% filter(month == 3) %>%
 left_join(lonlat)
mean_mar <- mean_mar %>%
  ungroup() %>%
  dplyr::select(-count,-id, -month)

coordinates(mean_mar) = c("x", "y")
mean_mar_raster <- rasterFromXYZ(mean_mar)

pred_mar <- tm_shape(mean_mar_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))

# actual data
mar_data <- train %>%
  filter(month == 3) %>%
  group_by(id) %>%
  summarise(count = mean(fire_count))

mar_data <- dataframe %>%
  left_join(mar_data) %>%
  dplyr::select(id,count) %>%
  mutate_all(~replace(., is.na(.), 0))

mar_data <- mar_data %>% left_join(lonlat) %>%
   dplyr::select(-id)

coordinates(mar_data) = c("x", "y")
mar_raster_actual <- rasterFromXYZ(mar_data)

actual_mar <- tm_shape(mar_raster_actual) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, 
            breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "March") +
  tm_legend(show = FALSE)

```

```{r map-rf1, fig.cap = "A map of the monthly fire counts of the actual (left) vs the predicted values (right) resulted from the random forest model for the training set.", warning = FALSE, message = FALSE}
tmap_arrange(actual_oct, pred_oct,
             actual_nov, pred_nov,
             actual_dec, pred_dec,
             actual_jan, pred_jan,
             actual_feb, pred_feb,
             actual_mar, pred_mar)
```

```{r}
test_final <- test %>%
  left_join(lonlat, by = "id") %>%
  dplyr::select(-year)
predicted_test <- test_final %>% bind_cols(pred =predicted)

test_oct <- predicted_test %>% filter(month == 10) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_oct) = c("x", "y")
test_oct_raster <- rasterFromXYZ(test_oct)

test_actual_oct <- tm_shape(test_oct_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,
            breaks = c(0,1.5,3)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "October") + 
  tm_legend(show = FALSE)

# pred data
test_oct_pred <- predicted_test %>%
  filter(month == 10) %>%
  ungroup() %>%
  dplyr::select(x,y,pred)

coordinates(test_oct_pred) = c("x", "y")
pred_oct_test_raster <- rasterFromXYZ(test_oct_pred)

test_pred_oct <- tm_shape(pred_oct_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, 
             breaks = c(0,1.5,3)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))


# for nov
test_nov <- predicted_test %>% filter(month == 11) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_nov) = c("x", "y")
test_nov_raster <- rasterFromXYZ(test_nov)

test_actual_nov <- tm_shape(test_nov_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,2.5,5)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "November") +
  tm_legend(show = FALSE)

# pred data
test_nov_pred <- predicted_test %>%
  filter(month == 11) %>%
  ungroup() %>%
  dplyr::select(x,y,pred)

coordinates(test_nov_pred) = c("x", "y")
pred_nov_test_raster <- rasterFromXYZ(test_nov_pred)

test_pred_nov <- tm_shape(pred_nov_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,2.5,5)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)+
  tm_layout(legend.position = c("right","top"))

# for dec
test_dec <- predicted_test %>% filter(month == 12) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_dec) = c("x", "y")
test_dec_raster <- rasterFromXYZ(test_dec)

test_actual_dec <- tm_shape(test_dec_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "December") +
  tm_legend(show = FALSE)

# pred data
test_dec_pred <- predicted_test %>%
  filter(month == 12) %>%
  ungroup() %>%
  dplyr::select(x,y,pred)

coordinates(test_dec_pred) = c("x", "y")
pred_dec_test_raster <- rasterFromXYZ(test_dec_pred)

test_pred_dec <- tm_shape(pred_dec_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))

# for jan
test_jan <- predicted_test %>% filter(month == 1) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_jan) = c("x", "y")
test_jan_raster <- rasterFromXYZ(test_jan)

test_actual_jan <- tm_shape(test_jan_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "January") +
  tm_legend(show = FALSE)

# pred data
test_jan_pred <- predicted_test %>%
  filter(month == 1) %>%
  ungroup() %>%
  dplyr::select(x,y,pred)

coordinates(test_jan_pred) = c("x", "y")
pred_jan_test_raster <- rasterFromXYZ(test_jan_pred)

test_pred_jan <- tm_shape(pred_jan_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,4,8)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))

# for feb
test_feb <- predicted_test %>% filter(month ==2) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_feb) = c("x", "y")
test_feb_raster <- rasterFromXYZ(test_feb)

test_actual_feb <- tm_shape(test_feb_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "February") +
  tm_legend(show = FALSE)

# pred data
test_feb_pred <- predicted_test %>%
  filter(month == 2) %>%
  ungroup()%>%
  dplyr::select(x,y,pred)

coordinates(test_feb_pred) = c("x", "y")
pred_feb_test_raster <- rasterFromXYZ(test_feb_pred)

test_pred_feb <- tm_shape(pred_feb_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,3,6)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))

# for march
test_mar <- predicted_test %>% filter(month == 3) %>%
  ungroup() %>%
  dplyr::select(x,y,fire_count)

coordinates(test_mar) = c("x", "y")
test_mar_raster <- rasterFromXYZ(test_mar)

test_actual_mar <- tm_shape(test_mar_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4, breaks = c(0,7,14)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(title = "March") +
  tm_legend(show = FALSE)

# pred data
test_mar_pred <- predicted_test %>%
  filter(month == 3) %>%
  ungroup() %>%
  dplyr::select(x,y,pred)

coordinates(test_mar_pred) = c("x", "y")
pred_mar_test_raster <- rasterFromXYZ(test_mar_pred)

test_pred_mar <- tm_shape(pred_mar_test_raster) +
  tm_raster(style = "cont", 
            palette = "seq",
                  alpha = 0.4,breaks = c(0,7,14)) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3) +
  tm_layout(legend.position = c("right","top"))
```

```{r map-rf-test, fig.cap = "A map of the monthly fire counts of the actual (left) vs the predicted values (right) resulted from the random forest model for the test set.", warning = FALSE, message = FALSE}
tmap_arrange( test_actual_oct, test_pred_oct,
              test_actual_nov, test_pred_nov,
              test_actual_dec, test_pred_dec,
              test_actual_jan, test_pred_jan,
              test_actual_feb, test_pred_feb,
              test_actual_mar, test_pred_mar)
```

Another limitation of our model is that there are a lot of zeros in the data, which might result to the under-prediction of fire counts. As previously mentioned, there are some high residuals which might be due to the huge amount of zeros in the data, which might affect the predictions for those with similar weather conditions but with a high fire counts. Additionally, the random forest is using variables which represent weather conditions, which might not account for accident-based fires. We might also be missing some variables that are useful for predicting the risk of fire, like distance to road. This could be a consideration for our future work to include more varibles, 



limitations: 
due to many 0s, this affect the predictions. we are predicting using weather variables --> accident based fire might not be accounted here. 

**lasso regression**
A lasso regresion was implemented to parse out the important variables. Depending on the penalty ($\lambda$) term imposed on the least square optimisation problem has the effect of shrinking (unimportnat) variables to zero/very small coefficient. When $\lambda = 0$, no parameters are elimated and the estimate equal to the one found in least squares. When $\lambda$ increases, more and more coefficients are set to 0 and eliminated. When $\lambda = \infty$, all coefficients are eliminated.

To choose a suitable $\lambda$ value, 5-fold cross validation is applied. Using a $\lambda$ grid consisting of 50 levels from 0 to 10 which is the default for `tune::penalty()`. For each cross-validation fold, the regularised lasso regression model is fitted and $R^2$ and $RMSE$ was recorded. The results is shown in Figure \@ref(fig:lasso-metric) *note results are on log10 scale. The $lambda$ value that minimises the RMSE was chosen which is found to be $1.0001$. 

```{r lasso-metric, fig.cap="mean RMSE(top) and R^2 (bottom) against penalty term"}
lasso_grid %>% 
  # obtain tuning results; across performance metrics (`.estimator`)
  tune::collect_metrics() %>% 
  # plot
  ggplot(aes(x = penalty,
             y = mean,
             colour = .metric)) +
  geom_errorbar(aes(ymin = mean - std_err,
                    ymax = mean + std_err)) +
  geom_line(size = 1.5) +
  # facet by `.metric`
  facet_wrap(~ .metric,
             scales = "free",
             nrow = 2) +
  # penalty in log10 scale
  scale_x_log10() +
  theme_bw() +
  theme(legend.position = "none")
```

To sum up, we extracted and plotted (in Figure \@ref(fig:vi)) the variable important scores for the predictors in the model. That is, the variables that coeffients remained consistently relatively higher despite the regularisation effect. Their effects (positive/negative) are coloured respectively. Correspondingly, the feature weights as $\lambda$ increases is shown in \@ref(fig:coefs-lasso)

```{r vi, fig.cap="variable importance plot from lasso regression"}
# --- plot variable importance
final_lasso %>% 
  parsnip::fit(train) %>% 
  # extract model fit
  workflows::extract_fit_parsnip() %>% 
  # compute variable importance scores for predictors
  vip::vi(lambda = lowest_rmse$penalty) %>% 
  # absolute `Importance`; for plotting
  mutate(Importance = abs(Importance)) %>% 
  # plot 
  ggplot(aes(x = Importance,
             y = fct_reorder(Variable,
                             Importance),
             fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL) +
  theme_bw() +
  colorspace::scale_fill_discrete_qualitative()
```

```{r coefs-lasso}
lasso_grid_coefs <- lasso_grid %>% 
  select(id, .extracts) %>% 
  unnest(.extracts) %>% 
  unnest(.extracts)

p <- lasso_grid_coefs %>% 
  ggplot() + 
  geom_line(aes(x = lambda, 
                y = estimate, 
                group = term,
                colour = term)) +
  scale_x_log10() +
  labs(title = "effect on lambda on feature coefficients") +
  theme_bw()  

plotly::ggplotly(p)
```

```{r vif-tab}
lm_fit <- stats::lm(formula = log(fire_count + 1) ~ . -id -year -month,
                    data = model_df2)

car::vif(lm_fit) %>% 
  as_tibble(rownames = "variable") %>% 
  rename(VIF = value) %>% 
  # extract variables with highest VIF 
  slice_max(VIF, 
            n = 6) %>% 
  kable(digits = 2,
        caption = "Variables with largest Variance Inflation Factors(VIF)") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

While lasso regression is a good regularisation technique to sieve out important variables, it is inadequate for modelling in our scenario. This is mainly due to the structure of our variables. The climate variables are highly correlated as one might expect. For example, with high `daily_rain` we would expect a lower `max_temp` or a variable with its lag variables are expectedly highly correlated. These relations exist across many of our variables thus indicating high multicollinearity. 

To demonstrate, we fit a linear model and computed the Variance Inflation Factor (VIF). The 6 variables with the highest VIF is shown in \@ref(tab:vif-tab). A general rule of thumb is that if VIF $> 10$ then multicollinearity is high (REF)[https://www.andreaperlato.com/mlpost/deal-multicollinearity-with-lasso-regression/]. Lasso's objective function provides unstable solutions in prescence of collinear features or features with very similar information. [REF](https://www.lexjansen.com/wuss/2018/131_Final_Paper_PDF.pdf).

Therefore, due to the inherent interplay between the variables, lasso regression is not used for modelling. For the same reason, generalised linear models attempted such as Poisson regression were ruled out.

# App (user-interface)
This app is an extension to an previously made `RShiny` app (publicly available on [Department of Econometrics and Business Statistics, Monash University](https://ebsmonash.shinyapps.io/VICfire/). The intent of the previous app was to increase accessibility to the general public and fire department personnel run the clustering model to predict the risk of bushfire; given a fire occur. Our complementary goal (as per Research grant) is to develop risk models to visualise and monitor potential fire ignitions and track fires from satellite hotspots, in real time, for 2021-2022 Victorian bushfire season.   

`RShiny` allows for elegant interactive exploratory plots and updates in real-time for swift decision making. It is also highly customisable to enhance users' interface. Furthermore, it supplies convenience function to assemble the html website in `R` and is easy to deploy. 

The current project builds on the "Fire Risk" Tab. On top of the historical bushfire information and bushfire `cause` prediction, this complementary addition serves to inform users with historical information risk and up-to-date predictions around bushfire risk. We maintained a similar design for the strucutre of the app- keeping separate tabs for historical information and predictions. This is to cater for different users who might be using the app. Fire personnels might be interested in the weather and landscape variables setting the scene conducive fire environment. While users would be interested in bushfire predictions while planning a trip.   

```{r app-hist-info, fig.cap="Bushfire Risk Information tab"}
knitr::include_graphics("data/report/bushfire-risk-info.png")
```

The current state of the historical bushfire risk Information tab is shown above. in Figure \@ref(fig:app-hist-info). User interactivity include choosing the bushfire seasons to overlay ignition points. User can also choose the months to compute number of bushfires from. Upon clicking a grid cell, the data table and plots are produced. The table provides information of the different weather and landscape variables. Plots show the historically the number of bushfires and values of each variable (max temperature in this case). 


```{r app-pred, fig.cap="rough plan for bushfire risk map"}
knitr::include_graphics("data/report/shiny_plan.png")
```

Additionally, a rough sketch of bushfire fire risk map in the app is shown above (Figure \@ref(fig:app-pred). It incorporates the random forest model to make predictions of the bushfire risk in a particular cell in real time. Furthermore, the user will be able to toggle the various variables and make forecasts under different scenarios. A detail is that not all cells shown will increase the same amount but instead at a relative rate (by %) to account for the fact that different places have different weather conditions.  

# Summary and future work
We explored some modelling to predict the risk of bushfire in Victoria for 2021-2022 based on weather conditions. Our best model is a random forest model which incorporates ..... (variables), which gives a training mean squared error of 1.216 and R-squared of 0.396. However, after applying to the test set, we got a slightly lower R-squared and higher MSE. The reason for this is might be because the model tends to over-fit the training set, resulting to less accurate predictions for the test set. Additionally, there are a lot of zeros in our data which results to under-predictions.  

--this is from the previous section--
Another limitation of our model is that there are a lot of zeros in the data, which might result to the under-prediction of fire counts. As previously mentioned, there are some high residuals which might be due to the huge amount of zeros in the data, which might affect the predictions for those with similar weather conditions but with a high fire counts. Additionally, the random forest is using variables which represent weather conditions, which might not account for accident-based fires. We might also be missing some variables that are useful for predicting the risk of fire, like distance to road. This could be a consideration for our future work to include more varibles, 
