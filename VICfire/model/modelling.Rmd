---
title: "modeling"
author: "Helen Evangelina"
date: "29/10/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(zoo)
library(raster)
library(sp)
library(broom)
library(randomForest)
library(tidymodels)
```

```{r}
data <- read.csv(here::here("VICfire/data/model_df.csv"))
```

```{r}
# checking for missing values
library(visdat)
vis_miss(data)
```

```{r}
# creating a raster for victoria
vic_raster <- raster(
  # no. of rows & columns (directly linked to resolution of grid cell)
  nrows = 20,
  ncols = 20,
  
  # bbox (bounding box of Victoria)
  xmn = 140.9617,
  xmx = 149.9763,
  ymn = -39.13396,
  ymx = -33.99605,
  
  # crs
  crs = "+proj=longlat +datum=WGS84"
  )
vic_raster[] <- 1:ncell(vic_raster)
# creating the lon & lat for each cell id
lonlat <- as.data.frame(coordinates(vic_raster)) %>%
  mutate(id = 1:400)
```

```{r}
# joining the data with lat and lon
data2 <-  data %>%
  left_join(lonlat, by = "id") 
```


## adding FOR_TYPE
-- this is not going to be added to the model --
```{r, eval = FALSE}
# this is not in the data folder bcs file is too large
forest <- raster(here::here('data/aus_for18_publish/aus_for18_publish/aus_for18/z001001.adf'))

# project to EPSG:3577
fire_points <- SpatialPoints(dplyr::select(data2, x, y), proj4string=CRS("+proj=longlat +datum=WGS84")) %>%
  spTransform(projection(forest))

# extract ID of rectangles
fire_forest_index <- extract(forest, fire_points)


# access attributes in forest 2018
fire_forest_info <- levels(forest) %>%
  as.data.frame()

fire_forest_info <- fire_forest_info %>%
  .[fire_forest_index,] %>%
  as_tibble()

# join back to the dataset
for (variable in names(fire_forest_info)){
  data2[[variable]] <- fire_forest_info[[variable]]
}
```

```{r, eval = FALSE}
# checking for missing values \
library(visdat)
data2 %>% vis_miss()
```
some of the data in the forest data has missing values (19.9% in total of NAs), which is quite a lot.

```{r, eval = FALSE}
library(rnaturalearth)
library(sf)
library(tmap)
au_map <- ne_states(country = 'Australia', returnclass = 'sf')
vic_map <- au_map[7,]

vic_map_sf <- vic_map %>%
  st_as_sf(coords = c("lon", "lat"))

data2_NA <- data2 %>%
  mutate(value = case_when(!is.na(FOREST) ~ 1,
                           is.na(FOREST) ~ 0)) %>%
  dplyr::select(x, y, value)

NA_raster <- rasterFromXYZ(data2_NA)

tm_shape(NA_raster$value) +
  tm_raster(style = "cont", 
            palette = "div",
                 # n = 5, # no. of colours 
                  alpha = 0.4) +
  tm_shape(vic_map_sf) +
  tmap::tm_borders(lwd = 3)
```
The missing values are on the boundaries of Victoria. Therefore, we can remove these values.

```{r, eval = FALSE}
# filtering out the NA values
data2 <- data2 %>%
  filter(!is.na(FOREST))
```

## creating lags
-- since we have monthly data, we can create a 2 months, 3 months, 6 months and a year lag.
2months -> average rainfall in the last 2 months

### for rain
```{r}
data_lagged <- data2 %>%
  arrange(id) %>%
  group_by(id) %>%
  mutate(rain2 = rollsumr(daily_rain, k = 2, fill = NA)/2,
         rain3 = rollsumr(daily_rain, k = 3, fill = NA)/3)
```
putting it into the model, rain3 and rain6 are not significant? but why after adding rain12, rain6 and rain12 become significant.

### for et
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(et_short_crop2 = rollsumr(et_short_crop, k = 2, fill = NA)/2,
         et_short_crop3 = rollsumr(et_short_crop, k = 3, fill = NA)/3)
```

### for max_temp
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(max_temp2 = rollsumr(max_temp, k = 2, fill = NA)/2,
         max_temp3 = rollsumr(max_temp, k = 3, fill = NA)/3)
```

### radiation
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(radiation2 = rollsumr(radiation, k = 2, fill = NA)/2,
         radiation3 = rollsumr(radiation, k = 3, fill = NA)/3)
```

### rh
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(rh2 = rollsumr(rh, k = 2, fill = NA)/2,
         rh3 = rollsumr(rh, k = 3, fill = NA)/3)
```

### si10
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(si102 = rollsumr(si10, k = 2, fill = NA)/2,
         si103 = rollsumr(si10, k = 3, fill = NA)/3)
```

### lai_hv
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(lai_hv2 = rollsumr(lai_hv, k = 2, fill = NA)/2,
         lai_hv3 = rollsumr(lai_hv, k = 3, fill = NA)/3)
```

### lai_lv
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(lai_lv2 = rollsumr(lai_lv, k = 2, fill = NA)/2,
         lai_lv3 = rollsumr(lai_lv, k = 3, fill = NA)/3)
```

### s0_pct
```{r}
data_lagged <- data_lagged %>%
  group_by(id) %>%
  mutate(s0_pct2 = rollsumr(s0_pct, k = 2, fill = NA)/2,
         s0_pct3 = rollsumr(s0_pct, k = 3, fill = NA)/3)
```


## modeling
### simple linear model
```{r}
# using count as the response
lm <- lm(fire_count ~ .-id - year, data = data)
summary(lm)
```

```{r}
# using log scale of count as the response
lm_log <- lm(log(fire_count+1) ~ .-id - year, data = data)
summary(lm_log)
```

```{r}
# using the added lag variables
linearmodel <- lm(log(fire_count+1) ~ .-id -x -y-year, data = data_lagged, na.action= na.exclude)
summary(linearmodel)
```
R-squared: 14.51% - not a good model

### linear model with only significant variables
```{r}
linearmodel2 <- lm(log(fire_count+1) ~ month +et_short_crop + radiation + si10 + lai_lv + forest + rain2 +et_short_crop2 + et_short_crop3 + max_temp2 + max_temp3 + radiation2+ rh2 +si102 + si103 +  lai_hv2 + lai_hv3 + lai_lv2 + lai_lv3, data = data_lagged, na.action = na.exclude)
summary(linearmodel2)
```
Ajd R-squared: 14.27%

```{r}
anova(linearmodel, linearmodel2)
```
If p-value > 0.05, do not rejetc null hypothesis that the smaller model is true --> smaller model is better. 
- linearmodel is better than linearmodel2

### checking if the variables are linear
```{r}
data_lagged %>%
  ggplot(aes(y = fire_count,
             x = daily_rain)) +
  geom_jitter() +
  geom_smooth()
```
```{r}
data_lagged %>%
  ggplot(aes(y = fire_count,
             x = rh)) +
  geom_jitter() +
  geom_smooth()
```

```{r}
data_lagged %>%
  ggplot(aes(y = fire_count,
             x = max_temp)) +
  geom_jitter() +
  geom_smooth()
```

```{r}
data_lagged %>%
  ggplot(aes(y = fire_count,
             x = radiation)) +
  geom_jitter() +
  geom_smooth()
```
```{r}
data_lagged %>%
  ggplot(aes(y = fire_count,
             x = lai_hv)) +
  geom_jitter() +
  geom_smooth()
```

### glm 
```{r}
glm <- glm(fire_count ~ . -id -x -y -year, data = data_lagged, family = poisson())
summary(glm)
```
- comparing with normal lm model:
```{r}
lm2 <- glm(fire_count ~ . -id -x -y -year, data = data_lagged, family = "gaussian")
summary(lm2)
```

both models have high deviance which indicates that the two models are not really a good model. But lm has way higher deviance, which means glm is better?

- plotting the model:
```{r}
augment_lm <- augment(lm2)
ggplot(lm2, aes(x = .fitted,
             y = .resid)) + 
  geom_point() +
  geom_smooth()

augment_glm <- augment(glm)
ggplot(augment_glm, aes(x = .fitted,
             y = .resid)) + 
  geom_point() +
  geom_smooth()
```

### Random Forest 
RF does not work with NAs. With NAs, rf will omit the NAs or impute the values. imputing the values wont work in this case. 

#### with lagged variables
-- month as factor?
```{r}
# omitting the NAs
data_lagged_omitted <- data_lagged %>% na.omit() %>%
  mutate(month = as.factor(month))

set.seed(2021)
rand1 <- randomForest(fire_count ~ .-year -id, data = data_lagged_omitted, importance = TRUE, mtry = 6, ntree = 500) 
rand1$predicted
```
MSE looks good?
MSE: 0.161
% var explaned: 41.08%


#### predicted values
the predicted values of our random forest model would be based on the average fitted values.



```{r}
predicted_values <- as.data.frame(rand1$predicted) %>% rename(`pred` = `rand1$predicted`)
predicted_data <- data_lagged_omitted %>% 
  bind_cols(predicted_values)
```

```{r}
dataframe <- data.frame(id = 1:400) 

pred_oct <- predicted_data %>% 
  dplyr::filter(month == 10) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_oct <- dataframe %>%
  left_join(pred_oct) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))

pred_nov <- predicted_data %>% 
  dplyr::filter(month == 11) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_nov <- dataframe %>%
  left_join(pred_nov) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))

pred_dec <- predicted_data %>% 
  dplyr::filter(month == 12) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_dec <- dataframe %>%
  left_join(pred_dec) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))

pred_jan <- predicted_data %>% 
  dplyr::filter(month == 1) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_jan <- dataframe %>%
  left_join(pred_jan) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))

pred_feb <- predicted_data %>% 
  dplyr::filter(month == 2) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_feb <- dataframe %>%
  left_join(pred_dec) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))

pred_mar <- predicted_data %>% 
  dplyr::filter(month == 3) %>%
  group_by(id) %>%
  summarise(pred_risk = mean(pred)) %>%
  mutate(count = exp(pred_risk))

data_mar <- dataframe %>%
  left_join(pred_mar) %>%
  dplyr::select(id, count) %>%
  mutate_all(~replace(., is.na(.), 0))
```

```{r}
write.csv(data_mar, here::here("VICfire/data/pred_march.csv"))
```


predicted counts are mostly 0? is this good?

```{r}
pred_mar
```


```{r}
importance(rand1)
varImpPlot(rand1)
```

## trying with a random forest model for each cell id
```{r}
data_lagged_171 <- data_lagged_omitted %>%
  filter(id == 171) %>%
  dplyr::select(-year, -x, -y)
set.seed(2021)
rf171 <- randomForest(log(fire_count+1) ~ .-id, data = data_lagged_171, importance = TRUE, mtry = 6, ntree = 500) 
pred171 <- rf171$predicted

typeof(rf171)

exp(pred171)
```
This makes much more sense.

```{r}
final_data <- data_lagged_omitted %>% 
  dplyr::select(-year, -x, -y)

no_of_id <- unique(data_lagged_omitted$id)

# making predictions
pred_values <- vector()
for (i in 1:length(no_of_id)) {
  data <- final_data %>% filter(id == no_of_id[i])
  rfmodel <-  randomForest(log(fire_count+1) ~ .-id, data = data, importance = TRUE, mtry = 6, ntree = 500) 
  predicted_values <- rfmodel$predicted 
  for (j in 1:length(predicted_values)) {
  pred_values <- append(pred_values, predicted_values[j])
  }
}
pred_count <- as.data.frame(exp(pred_values)-1) %>%
  rename(`pred_count` = `exp(pred_values)-1`)
final_data <- final_data %>%
  bind_cols(pred_count) %>%
  dplyr::select(fire_count, pred_count)
         

min(pred_count)
max(pred_count)
pred_count
arrange(pred_count, -`exp(pred_values)-1`)

tibble(pred_count = exp(pred_values) - 1) %>%
  arrange(-pred_count) %>% View()
View(final_data)

```

Model each month? 


```{r}
rfmodel_id <- rfmodel[[1]]
  data_id <- final_data %>% filter(id == no_of_id[1])
  predicted_values <- as.data.frame(rfmodel_id$predicted) %>%
    rename(`pred` = `rfmodel_id$predicted`)
rfmodel_id$predicted
data_id
rfmodel_id
```


--- with important variables ---- 
```{r}

set.seed(2021)
rand2 <- randomForest(log(fire_count+1) ~ x + y + radiation + month + daily_rain + rain3 + et_short_crop + s0_pct + s0_pct3 + s0_pct2+ rh + max_temp + rh3 + et_short_crop2 + et_short_crop3 + rain2 + si10 + max_temp2 + radiation2 + radiation3 + si103 + max_temp2 + lai_lv3, data = data_lagged_omitted, importance = TRUE, mtry = 6) 
rand2
```
41.36%
MSR 0.1611

the rf model with only the top important variables is slightly better than rf model using all of the variables. 

forest surprisingly isnt significant?

#### without lagged variables
```{r}
data_omitted <- data2 %>% na.omit()
rand_ori <- randomForest(log(fire_count+1) ~ . -id -year, data = data_omitted, importance = TRUE, mtry = 5) 
rand_ori
```
better than using the lagged data?
% var explained: 40.8%, MSR: 0.155

should we look at MSR or % var explained?

```{r}
importance(rand_ori)
varImpPlot(rand_ori)
```
```{r}
library(caret)

x <- data_omitted %>% dplyr::select(-fire_count)
y <- data_omitted$fire_count

tuneRF(x, y)
```

```{r}
x2 <- data_lagged_omitted %>% dplyr::select(-fire_count)
y2 <- data_lagged_omitted$fire_count

tuneRF(x2, y2)
```

## writing the data to csv files
```{r}
# the lag data
write.csv(data_lagged, here::here("VICfire/data/final_data_lag.csv"))

# the non-lag data
write.csv(data2, here::here("VICfire/data/final_data.csv"))
```

